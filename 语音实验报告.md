# 语音实验报告

高祎珂2011743

## 运行结果截图

根据给出的函数，使用云服务器，设置epoch为20，进行模型训练可以得到结果如下图所示：

![image-20230412231709804](C:\Users\26937\AppData\Roaming\Typora\typora-user-images\image-20230412231709804.png)



## 训练集和验证集上的loss曲线

设置epoch为20，绘制训练集和验证集的loss图像如下图所示。从图中我们可以看出，在训练过程中，训练集和验证集的loss基本呈减小趋势，也就是模型在不断优化，在epoch为20的时候，模型基本已经收敛。在训练过程中，训练集的loss会比验证集上的loss小。

<img src="C:\Users\26937\AppData\Roaming\Typora\typora-user-images\image-20230412231429942.png" alt="image-20230412231429942" style="zoom: 80%;" />

<center style="color:#000000;">训练集上的loss曲线</center>

<img src="C:\Users\26937\AppData\Roaming\Typora\typora-user-images\image-20230412231459393.png" alt="image-20230412231459393" style="zoom:80%;" />

<center style="color:#000000;">验证集上的loss曲线</center>

## 计算困惑度

对应代码如下：

```python
model = torch.load('model.pt')
def calPPL(sent):
    idsent = [get_wid(w2i, x, add_vocab = False) for x in sent.strip().split(" ")]
    loss = calc_sent_loss(idsent)
    num_words = len(idsent)
    print("ppl of '%s' = %.4f" % (sent,math.exp(loss.data/num_words)))
calPPL("Jane went to the store")
calPPL("store to Jane went the")
```

首先将句子装换为字典序号，然后加载训练好的模型进行前向传播，计算交叉熵损失。最后，根据公式算出 ppl。

使用epoch为20的模型计算得到的困惑度值如下图所示：

![image-20230412235027679](C:\Users\26937\AppData\Roaming\Typora\typora-user-images\image-20230412235027679.png)

